{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01097a8f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c143d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ce80d",
   "metadata": {},
   "source": [
    "# Student Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814d892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, 3, padding=1), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, 3, padding=1), torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2),\n",
    "            torch.nn.Conv2d(64, 64, 3, padding=1), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, 3, padding=1), torch.nn.ReLU(),\n",
    "            torch.nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        )\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 32, 3, padding=1), torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 3, 3, padding=1), torch.nn.Tanh()  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return (x + 1) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105aed17",
   "metadata": {},
   "source": [
    "# Loading Weights for Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c49c5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StudentCNN(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "student_A = StudentCNN().to(device)\n",
    "student_B = StudentCNN().to(device)\n",
    "student_A.load_state_dict(torch.load(r\"C:\\Users\\atole\\OneDrive\\Desktop\\Python\\Train_A.pth\"))\n",
    "student_B.load_state_dict(torch.load(r\"C:\\Users\\atole\\OneDrive\\Desktop\\Python\\Train_B.pth\"))\n",
    "student_A.eval()\n",
    "student_B.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5069e1",
   "metadata": {},
   "source": [
    "# Loop to test the model and evaluating performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c97480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Ensemble on Test Set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 198/198 [00:43<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Ensemble SSIM on Test Set: 0.9177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_path = r\"C:\\Users\\atole\\OneDrive\\Desktop\\Python\\Working Dataset\\test\"\n",
    "test_files = os.listdir(test_path)\n",
    "ssim_total = 0.0\n",
    "\n",
    "print(\"Running Ensemble on Test Set\")\n",
    "\n",
    "for fname in tqdm(test_files, desc=\"Test\"):\n",
    "    img = cv2.imread(os.path.join(test_path, fname))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    h, w = h - h % 8, w - w % 8\n",
    "    gt = cv2.resize(img, (w, h))\n",
    "    lr = cv2.resize(gt, (w//2, h//2), interpolation=cv2.INTER_LINEAR)\n",
    "    input_img = cv2.resize(lr, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    input_tensor = to_tensor(input_img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_A = student_A(input_tensor)\n",
    "        out_B = student_B(input_tensor)\n",
    "        output = (out_A + out_B) / 2.0\n",
    "        output_img = output.squeeze(0).clamp(0, 1).cpu().numpy()\n",
    "        gt_img = to_tensor(gt).numpy()\n",
    "        output_img = np.transpose(output_img, (1, 2, 0))\n",
    "        gt_img = np.transpose(gt_img, (1, 2, 0))\n",
    "        score = ssim(output_img, gt_img, channel_axis=2, data_range=1.0, win_size=11)\n",
    "        ssim_total += score\n",
    "\n",
    "avg_ssim = ssim_total / len(test_files)\n",
    "print(f\"\\n Final Ensemble SSIM on Test Set: {avg_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b55b9",
   "metadata": {},
   "source": [
    "# Loop to showcase images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9749170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Ensemble on Showcase Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Showcase: 100%|██████████| 50/50 [00:16<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Average SSIM on Showcase Set (Ensemble): 0.9146\n",
      " Saved ensemble outputs to: C:\\Users\\atole\\OneDrive\\Desktop\\Python\\Output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "showcase_path = r\"C:\\Users\\atole\\OneDrive\\Desktop\\Python\\Working Dataset\\showcase\"\n",
    "image_files = os.listdir(showcase_path)\n",
    "ssim_total = 0.0\n",
    "\n",
    "save_path = r\"C:\\Users\\atole\\OneDrive\\Desktop\\Python\\Output\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "print(\"Running Ensemble on Showcase Set:\")\n",
    "\n",
    "for i, fname in enumerate(tqdm(image_files, desc=\" Showcase\")):\n",
    "    img = cv2.imread(os.path.join(showcase_path, fname))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    h, w = h - h % 8, w - w % 8\n",
    "    gt = cv2.resize(img, (w, h))\n",
    "    lr = cv2.resize(gt, (w//2, h//2), interpolation=cv2.INTER_LINEAR)\n",
    "    input_img = cv2.resize(lr, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "    input_tensor = to_tensor(input_img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_A = student_A(input_tensor)\n",
    "        out_B = student_B(input_tensor)\n",
    "        output = (out_A + out_B) / 2.0\n",
    "        output_img = output.squeeze(0).clamp(0, 1).cpu().numpy()\n",
    "        gt_img = to_tensor(gt).numpy()\n",
    "        output_img = np.transpose(output_img, (1, 2, 0))\n",
    "        gt_img = np.transpose(gt_img, (1, 2, 0))\n",
    "        score = ssim(output_img, gt_img, channel_axis=2, data_range=1.0, win_size=11)\n",
    "        ssim_total += score\n",
    "\n",
    "    output_bgr = cv2.cvtColor((output_img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(f\"{save_path}/{fname}\", output_bgr)\n",
    "    \n",
    "\n",
    "avg_ssim = ssim_total / len(image_files)\n",
    "print(f\"\\n Average SSIM on Showcase Set (Ensemble): {avg_ssim:.4f}\")\n",
    "print(f\" Saved ensemble outputs to: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
